{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNDsZH8g5N1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2712398-a527-46ef-cfbe-ee162b343a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-465ce396b91b>:57: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(filepath)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 128975 entries, 0 to 128974\n",
            "Data columns (total 24 columns):\n",
            " #   Column              Non-Null Count   Dtype  \n",
            "---  ------              --------------   -----  \n",
            " 0   index               128975 non-null  int64  \n",
            " 1   Order ID            128975 non-null  object \n",
            " 2   Date                128975 non-null  object \n",
            " 3   Status              128975 non-null  object \n",
            " 4   Fulfilment          128975 non-null  object \n",
            " 5   Sales Channel       128975 non-null  object \n",
            " 6   ship-service-level  128975 non-null  object \n",
            " 7   Style               128975 non-null  object \n",
            " 8   SKU                 128975 non-null  object \n",
            " 9   Category            128975 non-null  object \n",
            " 10  Size                128975 non-null  object \n",
            " 11  ASIN                128975 non-null  object \n",
            " 12  Courier Status      122103 non-null  object \n",
            " 13  Qty                 128975 non-null  int64  \n",
            " 14  currency            121180 non-null  object \n",
            " 15  Amount              121180 non-null  float64\n",
            " 16  ship-city           128942 non-null  object \n",
            " 17  ship-state          128942 non-null  object \n",
            " 18  ship-postal-code    128942 non-null  float64\n",
            " 19  ship-country        128942 non-null  object \n",
            " 20  promotion-ids       79822 non-null   object \n",
            " 21  B2B                 128975 non-null  bool   \n",
            " 22  fulfilled-by        39277 non-null   object \n",
            " 23  Unnamed: 22         79925 non-null   object \n",
            "dtypes: bool(1), float64(2), int64(2), object(19)\n",
            "memory usage: 22.8+ MB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'Order ID' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Date' converted to datetime.\n",
            "Column 'Status' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Fulfilment' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Sales Channel ' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'ship-service-level' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Style' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'SKU' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Category' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Size' set to categorical with missing filled as 'Unknown'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column 'ASIN' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Courier Status' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'currency' set to categorical with missing filled as 'Unknown'.\n",
            "Numeric column 'Amount' missing values filled with median (605.0).\n",
            "Numeric column 'Amount' rounded to 2 decimals.\n",
            "Column 'ship-city' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'ship-state' set to categorical with missing filled as 'Unknown'.\n",
            "Numeric column 'ship-postal-code' missing values filled with median (500033.0).\n",
            "Numeric column 'ship-postal-code' rounded to 2 decimals.\n",
            "Column 'ship-country' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'promotion-ids' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'fulfilled-by' set to categorical with missing filled as 'Unknown'.\n",
            "Column 'Unnamed: 22' set to categorical with missing filled as 'Unknown'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n",
            "<ipython-input-1-465ce396b91b>:76: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[col] = pd.to_datetime(df[col], errors='raise')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after cleaning:\n",
            "index                 0\n",
            "Order ID              0\n",
            "Date                  0\n",
            "Status                0\n",
            "Fulfilment            0\n",
            "Sales Channel         0\n",
            "ship-service-level    0\n",
            "Style                 0\n",
            "SKU                   0\n",
            "Category              0\n",
            "Size                  0\n",
            "ASIN                  0\n",
            "Courier Status        0\n",
            "Qty                   0\n",
            "currency              0\n",
            "Amount                0\n",
            "ship-city             0\n",
            "ship-state            0\n",
            "ship-postal-code      0\n",
            "ship-country          0\n",
            "promotion-ids         0\n",
            "B2B                   0\n",
            "fulfilled-by          0\n",
            "Unnamed: 22           0\n",
            "dtype: int64\n",
            "\n",
            "--- Groq API Cleaning Instructions ---\n",
            "Data Cleaning and Transformation Steps\n",
            "=====================================\n",
            "\n",
            "Based on the provided data summary, the following steps are recommended to clean and transform the dataset for visualization in Power BI:\n",
            "\n",
            "### Step 1: Handle Missing Values\n",
            "\n",
            "*   Check for missing values in the dataset using the `isnull()` or `isna()` function in Python.\n",
            "*   Decide on a strategy to handle missing values, such as:\n",
            "    *   Dropping rows with missing values using `dropna()`.\n",
            "    *   Filling missing values with mean or median values using `fillna()`.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "# Assuming df is the DataFrame\n",
            "df = df.dropna()  # Drop rows with missing values\n",
            "```\n",
            "\n",
            "### Step 2: Convert Date/Time Formats\n",
            "\n",
            "*   Convert the `Date` column to a datetime format using the `pd.to_datetime()` function.\n",
            "*   Extract relevant date components, such as year, month, or day, as separate columns.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "df['Date'] = pd.to_datetime(df['Date'])\n",
            "df['Year'] = df['Date'].dt.year\n",
            "df['Month'] = df['Date'].dt.month\n",
            "df['Day'] = df['Date'].dt.day\n",
            "```\n",
            "\n",
            "### Step 3: Round Numeric Values\n",
            "\n",
            "*   Identify columns that require rounding, such as `Amount` or `Qty`.\n",
            "*   Use the `round()` function to round these values to a specified number of decimal places.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "df['Amount'] = df['Amount'].round(2)  # Round to 2 decimal places\n",
            "df['Qty'] = df['Qty'].round(0)  # Round to 0 decimal places\n",
            "```\n",
            "\n",
            "### Step 4: Convert Data Types\n",
            "\n",
            "*   Convert data types as needed, such as:\n",
            "    *   Converting `Status` and `Courier Status` columns to categorical data types using `pd.Categorical()`.\n",
            "    *   Converting `ship-city` and `ship-state` columns to string data types using `astype('str')`.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "df['Status'] = pd.Categorical(df['Status'])\n",
            "df['Courier Status'] = pd.Categorical(df['Courier Status'])\n",
            "df['ship-city'] = df['ship-city'].astype('str')\n",
            "df['ship-state'] = df['ship-state'].astype('str')\n",
            "```\n",
            "\n",
            "### Step 5: Remove Unnecessary Columns\n",
            "\n",
            "*   Identify columns that are not necessary for the analysis, such as `Unnamed: 22`.\n",
            "*   Drop these columns using the `drop()` function.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "df = df.drop(columns=['Unnamed: 22'])\n",
            "```\n",
            "\n",
            "### Step 6: Rename Columns\n",
            "\n",
            "*   Rename columns to make them more descriptive and user-friendly.\n",
            "*   Use the `rename()` function to rename columns.\n",
            "\n",
            "Example:\n",
            "```python\n",
            "df = df.rename(columns={'ship-service-level': 'Service Level', \n",
            "                        'ship-city': 'City', \n",
            "                        'ship-state': 'State'})\n",
            "```\n",
            "\n",
            "By following these steps, you can clean and transform your dataset to make it ready for visualization in Power BI.\n",
            "\n",
            "Full Code\n",
            "```python\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "\n",
            "# Load the data\n",
            "df = pd.read_csv('data.csv')\n",
            "\n",
            "# Handle missing values\n",
            "df = df.dropna()\n",
            "\n",
            "# Convert date/time formats\n",
            "df['Date'] = pd.to_datetime(df['Date'])\n",
            "df['Year'] = df['Date'].dt.year\n",
            "df['Month'] = df['Date'].dt.month\n",
            "df['Day'] = df['Date'].dt.day\n",
            "\n",
            "# Round numeric values\n",
            "df['Amount'] = df['Amount'].round(2)\n",
            "df['Qty'] = df['Qty'].round(0)\n",
            "\n",
            "# Convert data types\n",
            "df['Status'] = pd.Categorical(df['Status'])\n",
            "df['Courier Status'] = pd.Categorical(df['Courier Status'])\n",
            "df['ship-city'] = df['ship-city'].astype('str')\n",
            "df['ship-state'] = df['ship-state'].astype('str')\n",
            "\n",
            "# Remove unnecessary columns\n",
            "df = df.drop(columns=['Unnamed: 22'])\n",
            "\n",
            "# Rename columns\n",
            "df = df.rename(columns={'ship-service-level': 'Service Level', \n",
            "                        'ship-city': 'City', \n",
            "                        'ship-state': 'State'})\n",
            "\n",
            "# Save the cleaned and transformed data\n",
            "df.to_csv('cleaned_data.csv', index=False)\n",
            "```\n",
            "--- End of Instructions ---\n",
            "\n",
            "Cleaned data saved to 'Cleaned_Data_For_PowerBI.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "\n",
        "#############################################\n",
        "# Optional: Groq API call for cleaning advice\n",
        "#############################################\n",
        "def get_groq_cleaning_instructions(data_summary):\n",
        "    \"\"\"\n",
        "    Uses the Groq API to generate cleaning instructions based on a data summary.\n",
        "    (Replace API_KEY and ensure the endpoint and model are correct per your Groq documentation.)\n",
        "    \"\"\"\n",
        "    API_KEY = \"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\"  # Replace with your actual key\n",
        "    API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    prompt = (\n",
        "        \"Based on the following data summary, provide data cleaning and transformation steps \"\n",
        "        \"so that the dataset is ready for visualization in Power BI. Ensure that missing values, \"\n",
        "        \"date/time formats, numeric rounding, and data types are handled appropriately.\\n\\n\"\n",
        "        f\"{data_summary}\"\n",
        "    )\n",
        "\n",
        "    payload = {\n",
        "        \"model\": \"llama-3.3-70b-versatile\",  # Use the model per your API reference\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(API_URL, json=payload, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            instructions = response.json().get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
        "            return instructions\n",
        "        else:\n",
        "            return f\"Error {response.status_code}: {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calling Groq API: {e}\"\n",
        "\n",
        "#############################################\n",
        "# Dynamic Data Cleaning Function\n",
        "#############################################\n",
        "def dynamic_clean_dataset(filepath):\n",
        "    \"\"\"\n",
        "    Loads a dataset (Excel or CSV), dynamically inspects and cleans the data,\n",
        "    and returns a cleaned DataFrame ready for Power BI.\n",
        "    \"\"\"\n",
        "    # Load the dataset based on file extension\n",
        "    try:\n",
        "        if filepath.lower().endswith((\".xlsx\", \".xls\")):\n",
        "            df = pd.read_excel(filepath)\n",
        "        elif filepath.lower().endswith(\".csv\"):\n",
        "            df = pd.read_csv(filepath)\n",
        "        else:\n",
        "            print(\"Unsupported file format. Please use Excel or CSV.\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(\"Error loading dataset:\", e)\n",
        "        return None\n",
        "\n",
        "    print(\"Original Data Info:\")\n",
        "    print(df.info())\n",
        "\n",
        "    # Process each column dynamically\n",
        "    for col in df.columns:\n",
        "        col_dtype = df[col].dtype\n",
        "\n",
        "        if col_dtype == 'object':\n",
        "            # Try converting to datetime if possible\n",
        "            try:\n",
        "                # If you know the format, specify it, e.g. format=\"%m/%d/%Y\"\n",
        "                df[col] = pd.to_datetime(df[col], errors='raise')\n",
        "                print(f\"Column '{col}' converted to datetime.\")\n",
        "            except Exception:\n",
        "                # If conversion fails, treat as text and convert to categorical\n",
        "                df[col] = df[col].astype('category')\n",
        "                # If you plan to fill missing values, add a default category first.\n",
        "                if \"Unknown\" not in df[col].cat.categories:\n",
        "                    df[col] = df[col].cat.add_categories(['Unknown'])\n",
        "                df[col] = df[col].fillna('Unknown')\n",
        "                print(f\"Column '{col}' set to categorical with missing filled as 'Unknown'.\")\n",
        "        elif np.issubdtype(col_dtype, np.number):\n",
        "            # For numeric columns, fill missing values with the median.\n",
        "            if df[col].isnull().any():\n",
        "                median_val = df[col].median()\n",
        "                df[col] = df[col].fillna(median_val)\n",
        "                print(f\"Numeric column '{col}' missing values filled with median ({median_val}).\")\n",
        "            # Round floats to 2 decimal places.\n",
        "            if pd.api.types.is_float_dtype(df[col]):\n",
        "                df[col] = df[col].round(2)\n",
        "                print(f\"Numeric column '{col}' rounded to 2 decimals.\")\n",
        "        else:\n",
        "            # For any other types, try filling missing values with the mode.\n",
        "            if df[col].isnull().any():\n",
        "                mode_series = df[col].mode()\n",
        "                fill_value = mode_series[0] if not mode_series.empty else \"Unknown\"\n",
        "                # If the column is categorical, ensure the fill_value is a valid category.\n",
        "                if hasattr(df[col], \"cat\"):\n",
        "                    if fill_value not in df[col].cat.categories:\n",
        "                        df[col] = df[col].cat.add_categories([fill_value])\n",
        "                df[col] = df[col].fillna(fill_value)\n",
        "                print(f\"Column '{col}' missing values filled with mode/default ({fill_value}).\")\n",
        "\n",
        "    # After processing, check for any remaining missing values.\n",
        "    missing_after = df.isnull().sum()\n",
        "    print(\"Missing values after cleaning:\")\n",
        "    print(missing_after)\n",
        "\n",
        "    # For any residual missing values, fill with a default value.\n",
        "    df = df.fillna(\"Unknown\")\n",
        "    return df\n",
        "\n",
        "#############################################\n",
        "# Main Routine\n",
        "#############################################\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify the dataset path (adjust the path as needed)\n",
        "    filepath = \"Amazon Sale Report.csv\"  # Change to your file path\n",
        "\n",
        "    # Dynamically clean the dataset\n",
        "    cleaned_df = dynamic_clean_dataset(filepath)\n",
        "    # Check if cleaning was successful before proceeding\n",
        "    if cleaned_df is None:\n",
        "        print(\"Data cleaning failed.\")\n",
        "        exit()  # Exit the script if cleaning fails\n",
        "\n",
        "    # (Optional) Generate a data summary for the Groq API\n",
        "    data_summary = cleaned_df.describe(include='all').to_string()\n",
        "    groq_instructions = get_groq_cleaning_instructions(data_summary)\n",
        "\n",
        "    print(\"\\n--- Groq API Cleaning Instructions ---\")\n",
        "    print(groq_instructions)\n",
        "    print(\"--- End of Instructions ---\\n\")\n",
        "\n",
        "    # Save the cleaned data to a CSV file (ready for Power BI)\n",
        "    output_file = \"Cleaned_Data_For_PowerBI.csv\"\n",
        "    cleaned_df.to_csv(output_file, index=False)\n",
        "    print(f\"Cleaned data saved to '{output_file}'.\")"
      ]
    }
  ]
}